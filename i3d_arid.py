# -*- coding: utf-8 -*-
"""i3d_ARID.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JNt0hxJ0NDoDEd-W18IyiYusIdnzGRv9
"""

!unzip -q /content/drive/MyDrive/ARID_v1_5_211015.zip -d /content/ARID

import torch
from torch.utils.data import Dataset, DataLoader
import cv2
import numpy as np
import os
from pathlib import Path

class ARIDDataset(Dataset):
    def __init__(self, split_file_path, base_path='/content/ARID/clips_v1.5/',
                 num_frames=64, frame_size=(224, 224), transform=None):
        """
        ARID Dataset loader

        Args:
            split_file_path: Path to split file (train/test/others)
            base_path: Base directory path for video clips
            num_frames: Number of frames to sample from each video
            frame_size: Target frame size (height, width)
            transform: Optional transforms to apply
        """
        self.base_path = base_path
        self.num_frames = num_frames
        self.frame_size = frame_size
        self.transform = transform

        # Parse split file
        self.samples = []
        with open(split_file_path, 'r') as f:
            for line in f.readlines():
                parts = line.strip().split()
                if len(parts) >= 3:
                    idx = parts[0]
                    class_label = int(parts[1])
                    rel_path = ' '.join(parts[2:])  # Handle paths with spaces
                    full_path = os.path.join(base_path, rel_path)
                    self.samples.append((full_path, class_label))

        self.num_classes = len(set([sample[1] for sample in self.samples]))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        video_path, label = self.samples[idx]

        # Load video frames
        frames = self._load_video_frames(video_path)

        if self.transform:
            frames = self.transform(frames)

        return frames, label

    def _load_video_frames(self, video_path):
        """Load and preprocess video frames"""
        cap = cv2.VideoCapture(video_path)
        frames = []

        # Get total frame count
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        if total_frames == 0:
            # Handle empty video - return zeros
            return torch.zeros(3, self.num_frames, *self.frame_size)

        # Sample frame indices uniformly
        if total_frames >= self.num_frames:
            frame_indices = np.linspace(0, total_frames - 1,
                                      self.num_frames, dtype=int)
        else:
            # Repeat frames if video is shorter than required
            frame_indices = np.tile(np.arange(total_frames),
                                  (self.num_frames // total_frames + 1))[:self.num_frames]

        # Read frames
        for frame_idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()

            if ret:
                # Convert BGR to RGB
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                # Resize frame
                frame = cv2.resize(frame, self.frame_size[::-1])  # cv2 uses (width, height)
                frames.append(frame)
            else:
                # Use last valid frame if reading fails
                if frames:
                    frames.append(frames[-1])
                else:
                    frames.append(np.zeros((*self.frame_size, 3), dtype=np.uint8))

        cap.release()

        # Convert to tensor: (frames, height, width, channels) -> (channels, frames, height, width)
        frames = np.stack(frames)
        frames = torch.from_numpy(frames).float()
        frames = frames.permute(3, 0, 1, 2)  # FHWC -> CFHW

        # Normalize to [0, 1]
        frames = frames / 255.0

        return frames

!git clone https://github.com/piergiaj/pytorch-i3d.git

import sys
sys.path.append('/content/pytorch-i3d')

from pytorch_i3d import InceptionI3d
import torch
import torch.nn as nn

class I3DClassifier(nn.Module):
    def __init__(self, num_classes=11, pretrained=True):
        super(I3DClassifier, self).__init__()

        # Load pre-trained I3D model
        # We will use the original I3D up to the final pooling layer
        self.i3d = InceptionI3d(400, in_channels=3)  # 400 is Kinetics classes

        if pretrained:
            # Load pre-trained weights, excluding the original logits layer
            state_dict = torch.load('./pytorch-i3d/models/rgb_imagenet.pt')
            # Remove the logits layer weights from the state dict
            state_dict = {k: v for k, v in state_dict.items() if 'logits' not in k}
            self.i3d.load_state_dict(state_dict, strict=False) # Use strict=False because we removed logits

        # Add AdaptiveAvgPool3d to reduce temporal and spatial dimensions
        self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))

        # Replace the final classifier with a Linear layer
        # The output features from I3D before logits is 1024
        self.fc = nn.Linear(1024, num_classes)


    def forward(self, x):
        # Pass through the I3D feature extractor
        x = self.i3d.extract_features(x) # Use extract_features to get output before logits

        # Apply adaptive average pooling
        x = self.avg_pool(x)

        # Flatten the tensor
        x = x.flatten(1) # Flatten starting from dimension 1 (channels)

        # Pass through the linear classification layer
        logits = self.fc(x)

        return logits

import torch.optim as optim
from torch.nn import CrossEntropyLoss

base_path='/content/ARID/clips_v1.5/'
split_dir='/content/ARID/list_cvt/split_0/'
batch_size=4
num_workers=2

train_dataset = ARIDDataset(
        split_file_path=os.path.join(split_dir, 'split0_train.txt'),
        base_path=base_path
    )

test_dataset = ARIDDataset(
        split_file_path=os.path.join(split_dir, 'split0_test.txt'),
        base_path=base_path
    )

len(train_dataset), len(test_dataset)

train_dataset[0][0].shape

train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )

test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

def train_model(model, train_loader, test_loader, num_epochs=50, device='cuda'):
    """Train the I3D model on ARID dataset"""

    model = model.to(device)
    criterion = CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)

            optimizer.zero_grad()
            outputs = model(data)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += targets.size(0)
            train_correct += (predicted == targets).sum().item()

        # Validation phase
        model.eval()
        test_loss = 0.0
        test_correct = 0
        test_total = 0

        with torch.no_grad():
            for data, targets in test_loader:
                data, targets = data.to(device), targets.to(device)
                outputs = model(data)
                loss = criterion(outputs, targets)

                test_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                test_total += targets.size(0)
                test_correct += (predicted == targets).sum().item()

        scheduler.step()

        print(f'Epoch [{epoch+1}/{num_epochs}]')
        print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {100*train_correct/train_total:.2f}%')
        print(f'Test Loss: {test_loss/len(test_loader):.4f}, Test Acc: {100*test_correct/test_total:.2f}%')
        print('-' * 60)

model = I3DClassifier(num_classes=11)
# Train model
# train_model(model, train_loader, test_loader)

model = model.to(device)
criterion = CrossEntropyLoss()
# Replace SGD with Adam optimizer
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)

epochs = 20

from tqdm.notebook import tqdm

for epoch in tqdm(range(epochs), desc="Epochs"):
    # Training phase
    model.train()
    train_loss = 0.0
    train_correct = 0
    train_total = 0

    for batch_idx, (data, targets) in enumerate(train_loader):
        print(f'Batch {batch_idx + 1}/{len(train_loader)}')

        # Move data to device
        data = data.to(device)
        targets = targets.to(device)

        # Forward pass
        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, targets)

        # Backward and optimize
        loss.backward()
        optimizer.step()

        # Metrics
        train_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        train_total += targets.size(0)
        train_correct += (predicted == targets).sum().item()

    # Validation phase
    model.eval()
    test_loss = 0.0
    test_correct = 0
    test_total = 0

    with torch.no_grad():
        for data, targets in test_loader:
            data = data.to(device)
            targets = targets.to(device)

            outputs = model(data)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            test_total += targets.size(0)
            test_correct += (predicted == targets).sum().item()

    # Step the scheduler
    scheduler.step()

    # Logging
    print(f'Epoch [{epoch + 1}/{epochs}]')
    print(f'Train Loss: {train_loss / len(train_loader):.4f}, '
          f'Train Acc: {100 * train_correct / train_total:.2f}%')
    print(f'Test Loss: {test_loss / len(test_loader):.4f}, '
          f'Test Acc: {100 * test_correct / test_total:.2f}%')
    print('-' * 60)

