{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12277203,
          "sourceType": "datasetVersion",
          "datasetId": 7736838
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook2b966dc779",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "prathamjain965_aridzip_path = kagglehub.dataset_download('prathamjain965/aridzip')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-AY6DOEFmbV",
        "outputId": "242b9c30-6767-43e4-b6ea-0dbfa52fcd13"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "print(prathamjain965_aridzip_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5yitIAooyZx",
        "outputId": "09bdc4f8-8f14-485f-fe18-548f34502356"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/aridzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install tensorboard\n",
        "!pip install fvcore\n",
        "!pip install simplejson\n",
        "!pip install av\n",
        "!pip install pytorchvideo"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD8AKiUulRR8",
        "outputId": "7f65b836-2a75-493f-9464-ebbe371959f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (3.2.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (3.20.1)\n",
            "Collecting av\n",
            "  Using cached av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Using cached av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "Installing collected packages: av\n",
            "Successfully installed av-14.4.0\n",
            "Collecting pytorchvideo\n",
            "  Using cached pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.1.5.post20221221)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (14.4.0)\n",
            "Collecting parameterized (from pytorchvideo)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.1.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo) (4.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo) (3.2.0)\n",
            "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: pytorchvideo\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188686 sha256=70265cab032b85d67b2651dcd898ec5eca14396f2926d79fa5008119a15464f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/6d/ae/d016375a73be141a0e11bb42289e2d0b046c35687fc8010ecc\n",
            "Successfully built pytorchvideo\n",
            "Installing collected packages: parameterized, pytorchvideo\n",
            "Successfully installed parameterized-0.9.0 pytorchvideo-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/slowfast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST0JxDEpl7FG",
        "outputId": "2da27e11-8146-4b9a-e7c2-6028e75ccb9f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'slowfast' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SlowFast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4v5D1HOnARk",
        "outputId": "ab23bc4d-4ed4-4c48-8a80-fb4df2c4b0a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SlowFast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py build develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCjbgb-7nDIY",
        "outputId": "fb760cfc-bddf-4ad7-94da-1178dbe86021"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running build\n",
            "running build_py\n",
            "creating build/lib/slowfast\n",
            "copying slowfast/__init__.py -> build/lib/slowfast\n",
            "creating build/lib/slowfast/config\n",
            "copying slowfast/config/defaults.py -> build/lib/slowfast/config\n",
            "copying slowfast/config/__init__.py -> build/lib/slowfast/config\n",
            "copying slowfast/config/custom_config.py -> build/lib/slowfast/config\n",
            "creating build/lib/slowfast/utils\n",
            "copying slowfast/utils/parser.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/ava_eval_helper.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/metrics.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/multiprocessing.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/__init__.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/meters.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/misc.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/lr_policy.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/multigrid.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/env.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/distributed.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/checkpoint.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/benchmark.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/c2_model_loading.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/logging.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/weight_init_helper.py -> build/lib/slowfast/utils\n",
            "copying slowfast/utils/bn_helper.py -> build/lib/slowfast/utils\n",
            "creating build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/random_erasing.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/ptv_datasets.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/build.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/mixup.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/charades.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/utils.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/__init__.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/ava_helper.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/decoder.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/video_container.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/loader.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/imagenet.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/multigrid_helper.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/kinetics.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/transform.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/rand_augment.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/ava_dataset.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/cv2_transform.py -> build/lib/slowfast/datasets\n",
            "copying slowfast/datasets/ssv2.py -> build/lib/slowfast/datasets\n",
            "creating build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/prediction_vis.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/video_visualizer.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/tensorboard_vis.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/utils.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/__init__.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/ava_demo_precomputed_boxes.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/async_predictor.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/predictor.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/gradcam_utils.py -> build/lib/slowfast/visualization\n",
            "copying slowfast/visualization/demo_loader.py -> build/lib/slowfast/visualization\n",
            "creating build/lib/slowfast/models\n",
            "copying slowfast/models/losses.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/contrastive.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/build.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/utils.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/__init__.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/masked.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/batchnorm_helper.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/operators.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/resnet_helper.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/head_helper.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/optimizer.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/custom_video_model_builder.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/common.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/reversible_mvit.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/stem_helper.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/ptv_model_builder.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/nonlocal_helper.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/attention.py -> build/lib/slowfast/models\n",
            "copying slowfast/models/video_model_builder.py -> build/lib/slowfast/models\n",
            "running develop\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating slowfast.egg-info\n",
            "writing slowfast.egg-info/PKG-INFO\n",
            "writing dependency_links to slowfast.egg-info/dependency_links.txt\n",
            "writing requirements to slowfast.egg-info/requires.txt\n",
            "writing top-level names to slowfast.egg-info/top_level.txt\n",
            "writing manifest file 'slowfast.egg-info/SOURCES.txt'\n",
            "reading manifest file 'slowfast.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'slowfast.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.11/dist-packages/slowfast.egg-link (link to .)\n",
            "Adding slowfast 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/SlowFast\n",
            "Processing dependencies for slowfast==1.0\n",
            "Searching for fairscale\n",
            "Reading https://pypi.org/simple/fairscale/\n",
            "Downloading https://files.pythonhosted.org/packages/c1/08/b3334d7b543ac10dcb129cef4f84723ab696725512f18d69ab3a784b0bf5/fairscale-0.4.13.tar.gz#sha256=1b797825c427f5dba92253fd0d8daa574e8bd651a2423497775fab1b30cfb768\n",
            "Best match: fairscale 0.4.13\n",
            "Processing fairscale-0.4.13.tar.gz\n",
            "Writing /tmp/easy_install-zig0jl5i/fairscale-0.4.13/setup.cfg\n",
            "Running fairscale-0.4.13/setup.py -q bdist_egg --dist-dir /tmp/easy_install-zig0jl5i/fairscale-0.4.13/egg-dist-tmp-a_21dil5\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'fairscale.clib.fused_adam_cuda' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'fairscale.clib.fused_adam_cuda' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'fairscale.clib.fused_adam_cuda' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'fairscale.clib.fused_adam_cuda' to be distributed and are\n",
            "        already explicitly excluding 'fairscale.clib.fused_adam_cuda' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "fairscale.experimental.nn.distributed_pipeline.__pycache__.trace.cpython-311: module MAY be using inspect.trace\n",
            "Adding fairscale 0.4.13 to easy-install.pth file\n",
            "Installing wgit script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/fairscale-0.4.13-py3.11.egg\n",
            "Searching for sklearn\n",
            "Reading https://pypi.org/simple/sklearn/\n",
            "Downloading https://files.pythonhosted.org/packages/46/1c/395a83ee7b2d2ad7a05b453872053d41449564477c81dc356f720b16eac4/sklearn-0.0.post12.tar.gz#sha256=54cff9e20839b7b202321178228af4d9388bedf78425d9299fd9ee170d68802e\n",
            "Best match: sklearn 0.0.post12\n",
            "Processing sklearn-0.0.post12.tar.gz\n",
            "Writing /tmp/easy_install-050vrfqx/sklearn-0.0.post12/setup.cfg\n",
            "Running sklearn-0.0.post12/setup.py -q bdist_egg --dist-dir /tmp/easy_install-050vrfqx/sklearn-0.0.post12/egg-dist-tmp-dyt08h3l\n",
            "error: Setup script exited with The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "rather than 'sklearn' for pip commands. \n",
            "\n",
            "Here is how to fix this error in the main use cases:\n",
            "- use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "- replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "  (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "- if the 'sklearn' package is used by one of your dependencies,\n",
            "  it would be great if you take some time to track which package uses\n",
            "  'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "- as a last resort, set the environment variable\n",
            "  SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "\n",
            "More information is available at\n",
            "https://github.com/scikit-learn/sklearn-pypi-package\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import slowfast; print('PySlowFast installed successfully')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV3OFnUInFI8",
        "outputId": "aa829395-1951-4e5e-d171-146a338ba5cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySlowFast installed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/pretrained_models"
      ],
      "metadata": {
        "id": "0IKhicKIn1mO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "fxFGlSq7n15x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = \"https://dl.fbaipublicfiles.com/pyslowfast/model_zoo/mvitv2/pysf_video_models/MViTv2_S_16x4_k400_f302660347.pyth\""
      ],
      "metadata": {
        "id": "sw8_EUhSn4mB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/pretrained_models/mvit_v2_s_kinetics400.pth {model_url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvWYNrrDn-y7",
        "outputId": "4ab7a5a9-fdcb-44c7-98cd-24784658a2c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-26 09:45:37--  https://dl.fbaipublicfiles.com/pyslowfast/model_zoo/mvitv2/pysf_video_models/MViTv2_S_16x4_k400_f302660347.pyth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.15, 13.226.210.25, 13.226.210.111, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 414835762 (396M) [binary/octet-stream]\n",
            "Saving to: ‘/content/pretrained_models/mvit_v2_s_kinetics400.pth’\n",
            "\n",
            "/content/pretrained 100%[===================>] 395.62M  60.7MB/s    in 6.5s    \n",
            "\n",
            "2025-06-26 09:45:44 (61.3 MB/s) - ‘/content/pretrained_models/mvit_v2_s_kinetics400.pth’ saved [414835762/414835762]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "sZBTmUq9oOQh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_arid_splits(arid_path):\n",
        "    \"\"\"\n",
        "    Parse your ARID dataset structure for evaluation\n",
        "    \"\"\"\n",
        "    # ARID v1.5 action categories\n",
        "    action_categories = [\n",
        "        'Drink', 'Jump', 'Pick', 'Pour', 'Push',\n",
        "        'Run', 'Sit', 'Stand', 'Turn', 'Walk', 'Wave'\n",
        "    ]\n",
        "\n",
        "    clips_path = os.path.join(arid_path, \"clips_v1.5\")\n",
        "    list_path = os.path.join(arid_path, \"list_cvt/split_0\")\n",
        "\n",
        "    # Parse test split file\n",
        "    test_data = []\n",
        "    test_file = os.path.join(list_path, \"split0_test.txt\")\n",
        "\n",
        "    with open(test_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                video_path = parts[2]  # e.g., \"action_folder/video_name.mp4\"\n",
        "                label = int(parts[1])\n",
        "                # Full path to video file\n",
        "                full_video_path = os.path.join(clips_path, video_path)\n",
        "                if os.path.exists(full_video_path):\n",
        "                    test_data.append({\n",
        "                        'video_path': video_path,  # Adjust path format\n",
        "                        'full_path': full_video_path,\n",
        "                        'label': label,\n",
        "                        'action': action_categories[label]\n",
        "                    })\n",
        "\n",
        "    return pd.DataFrame(test_data), action_categories\n",
        "\n",
        "# Set your ARID dataset path\n",
        "ARID_PATH = prathamjain965_aridzip_path  # Adjust this to your dataset location\n",
        "test_df, action_classes = parse_arid_splits(ARID_PATH)\n",
        "\n",
        "print(f\"Found {len(test_df)} test videos\")\n",
        "print(f\"Action classes: {action_classes}\")\n",
        "print(\"Sample entries:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKaN7VqXoTk0",
        "outputId": "4c3d25e2-1989-45ec-c79f-8355709324ed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2011 test videos\n",
            "Action classes: ['Drink', 'Jump', 'Pick', 'Pour', 'Push', 'Run', 'Sit', 'Stand', 'Turn', 'Walk', 'Wave']\n",
            "Sample entries:\n",
            "          video_path                                          full_path  \\\n",
            "0   Run/Run_13_1.mp4  /kaggle/input/aridzip/clips_v1.5/Run/Run_13_1.mp4   \n",
            "1  Run/Run_13_10.mp4  /kaggle/input/aridzip/clips_v1.5/Run/Run_13_10...   \n",
            "2  Run/Run_13_11.mp4  /kaggle/input/aridzip/clips_v1.5/Run/Run_13_11...   \n",
            "3  Run/Run_13_12.mp4  /kaggle/input/aridzip/clips_v1.5/Run/Run_13_12...   \n",
            "4  Run/Run_13_13.mp4  /kaggle/input/aridzip/clips_v1.5/Run/Run_13_13...   \n",
            "\n",
            "   label action  \n",
            "0      5    Run  \n",
            "1      5    Run  \n",
            "2      5    Run  \n",
            "3      5    Run  \n",
            "4      5    Run  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create evaluation script\n",
        "evaluation_code = '''\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Video processing\n",
        "def load_video_frames(video_path, num_frames=16, sample_rate=4):\n",
        "    \"\"\"\n",
        "    Load video frames for MViTv2 input\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate frame indices to sample\n",
        "    total_needed = num_frames * sample_rate\n",
        "    if frame_count >= total_needed:\n",
        "        start_idx = (frame_count - total_needed) // 2\n",
        "        indices = list(range(start_idx, start_idx + total_needed, sample_rate))\n",
        "    else:\n",
        "        # Repeat frames if video is too short\n",
        "        indices = np.linspace(0, frame_count-1, num_frames, dtype=int)\n",
        "\n",
        "    for i, frame_idx in enumerate(indices):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frames.append(frame)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Pad or truncate to exact number of frames needed\n",
        "    while len(frames) < num_frames:\n",
        "        frames.append(frames[-1] if frames else np.zeros((224, 224, 3), dtype=np.uint8))\n",
        "    frames = frames[:num_frames]\n",
        "\n",
        "    return np.array(frames)\n",
        "\n",
        "def preprocess_frames(frames):\n",
        "    \"\"\"\n",
        "    Preprocess frames for MViTv2\n",
        "    \"\"\"\n",
        "    # Convert to float and normalize to [0, 1]\n",
        "    frames = frames.astype(np.float32) / 255.0\n",
        "\n",
        "    # Normalize with ImageNet stats (commonly used for MViTv2)\n",
        "    mean = np.array([0.45, 0.45, 0.45])\n",
        "    std = np.array([0.225, 0.225, 0.225])\n",
        "\n",
        "    frames = (frames - mean) / std\n",
        "\n",
        "    # Convert to tensor and rearrange dimensions: T H W C -> C T H W\n",
        "    frames_tensor = torch.from_numpy(frames).permute(3, 0, 1, 2)\n",
        "\n",
        "    return frames_tensor\n",
        "\n",
        "def create_mvitv2_model(num_classes=11, pretrained_path=None):\n",
        "    \"\"\"\n",
        "    Create MViTv2 model for evaluation\n",
        "    \"\"\"\n",
        "    # Using torchvision's MViTv2 as base\n",
        "    from torchvision.models.video import mvit_v2_s\n",
        "\n",
        "    # Load base model\n",
        "    model = mvit_v2_s(weights=None)  # No automatic pretrained weights\n",
        "\n",
        "    # Modify classifier for ARID dataset (11 classes)\n",
        "    model.head[-1] = nn.Linear(model.head[-1].in_features, num_classes)\n",
        "\n",
        "    # Load pretrained weights if provided\n",
        "    if pretrained_path and os.path.exists(pretrained_path):\n",
        "        try:\n",
        "            # Load weights\n",
        "            checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
        "\n",
        "            # Handle different checkpoint formats\n",
        "            if isinstance(checkpoint, dict):\n",
        "                if 'model_state' in checkpoint:\n",
        "                    state_dict = checkpoint['model_state']\n",
        "                elif 'state_dict' in checkpoint:\n",
        "                    state_dict = checkpoint['state_dict']\n",
        "                else:\n",
        "                    state_dict = checkpoint\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "\n",
        "            # Load weights with strict=False to ignore classifier layer mismatch\n",
        "            model.load_state_dict(state_dict, strict=False)\n",
        "            print(f\"Loaded pretrained weights from {pretrained_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load pretrained weights: {e}\")\n",
        "            print(\"Proceeding with random initialization...\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_arid_dataset(test_df, model, device, action_classes):\n",
        "    \"\"\"\n",
        "    Evaluate MViTv2 on ARID test set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    print(\"Starting evaluation...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Evaluating\"):\n",
        "            try:\n",
        "                # Load and preprocess video\n",
        "                frames = load_video_frames(row['full_path'])\n",
        "                frames_tensor = preprocess_frames(frames)\n",
        "\n",
        "                # Add batch dimension\n",
        "                input_tensor = frames_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_tensor)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                all_predictions.append(predicted.cpu().item())\n",
        "                all_labels.append(row['label'])\n",
        "                all_probs.append(probs.cpu().numpy()[0])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {row['full_path']}: {e}\")\n",
        "                # Use dummy prediction in case of error\n",
        "                all_predictions.append(0)\n",
        "                all_labels.append(row['label'])\n",
        "                all_probs.append(np.zeros(len(action_classes)))\n",
        "\n",
        "    return all_predictions, all_labels, np.array(all_probs)\n",
        "\n",
        "def calculate_metrics(predictions, labels, probs, action_classes):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics\n",
        "    \"\"\"\n",
        "    # Top-1 accuracy\n",
        "    top1_acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Top-5 accuracy\n",
        "    top5_acc = top_k_accuracy(probs, labels, k=min(5, len(action_classes)))\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(\n",
        "        labels, predictions,\n",
        "        target_names=action_classes,\n",
        "        digits=4,\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'top1_accuracy': top1_acc,\n",
        "        'top5_accuracy': top5_acc,\n",
        "        'classification_report': report,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "def top_k_accuracy(probs, labels, k=5):\n",
        "    \"\"\"Calculate top-k accuracy\"\"\"\n",
        "    top_k_preds = np.argsort(probs, axis=1)[:, -k:]\n",
        "    correct = 0\n",
        "    for i, label in enumerate(labels):\n",
        "        if label in top_k_preds[i]:\n",
        "            correct += 1\n",
        "    return correct / len(labels)\n",
        "\n",
        "def plot_results(cm, action_classes, results):\n",
        "    \"\"\"\n",
        "    Plot evaluation results\n",
        "    \"\"\"\n",
        "    # Confusion matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=action_classes,\n",
        "                yticklabels=action_classes, cmap='Blues')\n",
        "    plt.title('Confusion Matrix - ARID Dataset Evaluation')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Per-class accuracy\n",
        "    per_class_acc = []\n",
        "    for i in range(len(action_classes)):\n",
        "        if cm[i].sum() > 0:\n",
        "            acc = cm[i][i] / cm[i].sum()\n",
        "        else:\n",
        "            acc = 0\n",
        "        per_class_acc.append(acc)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    bars = plt.bar(action_classes, per_class_acc)\n",
        "    plt.title('Per-Class Accuracy - ARID Dataset')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Action Class')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, acc in zip(bars, per_class_acc):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall Results:\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1_accuracy']:.4f} ({results['top1_accuracy']*100:.2f}%)\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5_accuracy']:.4f} ({results['top5_accuracy']*100:.2f}%)\")\n",
        "\n",
        "# Main evaluation function\n",
        "def main():\n",
        "    # Load test data (assuming test_df and action_classes are already defined)\n",
        "    print(f\"Evaluating on {len(test_df)} test videos\")\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create model\n",
        "    pretrained_path = \"/content/pretrained_models/mvit_v2_s_kinetics400.pth\"\n",
        "    model = create_mvitv2_model(num_classes=11, pretrained_path=pretrained_path)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Evaluate\n",
        "    predictions, labels, probs = evaluate_arid_dataset(test_df, model, device, action_classes)\n",
        "\n",
        "    # Calculate metrics\n",
        "    results = calculate_metrics(predictions, labels, probs, action_classes)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\\\nClassification Report:\")\n",
        "    print(results['classification_report'])\n",
        "\n",
        "    # Plot results\n",
        "    plot_results(results['confusion_matrix'], action_classes, results)\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()\n",
        "'''\n",
        "\n",
        "# Save the evaluation script\n",
        "with open('/content/SlowFast/evaluate_arid_mvitv2.py', 'w') as f:\n",
        "    f.write(evaluation_code)\n",
        "\n",
        "print(\"Created evaluation script\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QlA0NK3siOl",
        "outputId": "ce0e08eb-2e4e-49fa-b1dc-d502143f16e3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created evaluation script\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the evaluation\n",
        "%cd /content/SlowFast\n",
        "\n",
        "# Run the evaluation\n",
        "exec(open('evaluate_arid_mvitv2.py').read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "JS3YTjhysoJT",
        "outputId": "6f7f30d9-f6e6-4094-c307-d869e5a8df19"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SlowFast\n",
            "Evaluating on 2011 test videos\n",
            "Using device: cpu\n",
            "Loaded pretrained weights from /content/pretrained_models/mvit_v2_s_kinetics400.pth\n",
            "Starting evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   0%|          | 1/2011 [00:01<40:58,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_1.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 2/2011 [00:02<38:53,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_10.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 3/2011 [00:03<41:29,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_11.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 4/2011 [00:05<42:42,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_12.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 5/2011 [00:06<45:04,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_13.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 6/2011 [00:08<56:51,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_14.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 7/2011 [00:10<55:15,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_15.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 8/2011 [00:11<52:54,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /kaggle/input/aridzip/clips_v1.5/Run/Run_13_16.mp4: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 8/2011 [00:12<50:52,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-31-1300727449.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run the evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate_arid_mvitv2.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mevaluate_arid_dataset\u001b[0;34m(test_df, model, device, action_classes)\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mload_video_frames\u001b[0;34m(video_path, num_frames, sample_rate)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "PrA97527stId"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_arid_splits(arid_path):\n",
        "    action_categories = [\n",
        "        'Drink', 'Jump', 'Pick', 'Pour', 'Push',\n",
        "        'Run', 'Sit', 'Stand', 'Turn', 'Walk', 'Wave'\n",
        "    ]\n",
        "    clips_path = os.path.join(arid_path, \"clips_v1.5\")\n",
        "    list_path = os.path.join(arid_path, \"list_cvt/split_0\")\n",
        "    test_file = os.path.join(list_path, \"split0_test.txt\")\n",
        "\n",
        "    test_data = []\n",
        "    with open(test_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 3:\n",
        "                idx_label = int(parts[1])\n",
        "                vid_rel = parts[2]\n",
        "                full_path = os.path.join(clips_path, vid_rel)\n",
        "                if os.path.exists(full_path):\n",
        "                    test_data.append({\n",
        "                        'full_path': full_path,\n",
        "                        'label': idx_label\n",
        "                    })\n",
        "    return pd.DataFrame(test_data), action_categories\n"
      ],
      "metadata": {
        "id": "muiCBQrfxWg6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video_frames(video_path, num_frames=16, sample_rate=4):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    total_needed = num_frames * sample_rate\n",
        "\n",
        "    if frame_count >= total_needed:\n",
        "        start = (frame_count - total_needed) // 2\n",
        "        indices = list(range(start, start + total_needed, sample_rate))\n",
        "    else:\n",
        "        indices = np.linspace(0, frame_count - 1, num_frames, dtype=int)\n",
        "\n",
        "    frames = []\n",
        "    for idx in indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame = cv2.resize(frame, (224, 224))\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "    # Pad/truncate to num_frames\n",
        "    while len(frames) < num_frames:\n",
        "        frames.append(frames[-1].copy())\n",
        "    return np.stack(frames[:num_frames], axis=0)\n"
      ],
      "metadata": {
        "id": "SVHTX-8nxZq_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_frames(frames):\n",
        "    # Convert to float32 and normalize to [0,1]\n",
        "    frames = frames.astype(np.float32) / 255.0\n",
        "    # Use float32 mean/std to avoid dtype mismatch\n",
        "    mean = np.array([0.45, 0.45, 0.45], dtype=np.float32)\n",
        "    std  = np.array([0.225, 0.225, 0.225], dtype=np.float32)\n",
        "    frames = (frames - mean) / std\n",
        "    # NHWC -> NCTHW\n",
        "    tensor = torch.from_numpy(frames).permute(3, 0, 1, 2)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "qUAr94F4xcCI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mvitv2_model(num_classes=11, pretrained_path=None):\n",
        "    from torchvision.models.video import mvit_v2_s\n",
        "    model = mvit_v2_s(weights=None)\n",
        "    # Load pretrained weights if available\n",
        "    if pretrained_path and os.path.exists(pretrained_path):\n",
        "        ckpt = torch.load(pretrained_path, map_location='cpu')\n",
        "        state = ckpt.get('model_state', ckpt.get('state_dict', ckpt))\n",
        "        model.load_state_dict(state, strict=False)\n",
        "        print(f\"Loaded pretrained weights from {pretrained_path}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "d5pXZxaVxdsZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wImeqSKEysM0",
        "outputId": "25beefcb-e02e-4147-af89-291c0f9bab9e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              full_path  label\n",
              "0     /kaggle/input/aridzip/clips_v1.5/Run/Run_13_1.mp4      5\n",
              "1     /kaggle/input/aridzip/clips_v1.5/Run/Run_13_10...      5\n",
              "2     /kaggle/input/aridzip/clips_v1.5/Run/Run_13_11...      5\n",
              "3     /kaggle/input/aridzip/clips_v1.5/Run/Run_13_12...      5\n",
              "4     /kaggle/input/aridzip/clips_v1.5/Run/Run_13_13...      5\n",
              "...                                                 ...    ...\n",
              "2006  /kaggle/input/aridzip/clips_v1.5/Push/Push_6_5...      4\n",
              "2007  /kaggle/input/aridzip/clips_v1.5/Push/Push_6_6...      4\n",
              "2008  /kaggle/input/aridzip/clips_v1.5/Push/Push_6_7...      4\n",
              "2009  /kaggle/input/aridzip/clips_v1.5/Push/Push_6_8...      4\n",
              "2010  /kaggle/input/aridzip/clips_v1.5/Push/Push_6_9...      4\n",
              "\n",
              "[2011 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7eb44d9-f7fa-4caa-a129-70e26a0c0563\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Run/Run_13_1.mp4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Run/Run_13_10...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Run/Run_13_11...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Run/Run_13_12...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Run/Run_13_13...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Push/Push_6_5...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Push/Push_6_6...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Push/Push_6_7...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Push/Push_6_8...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010</th>\n",
              "      <td>/kaggle/input/aridzip/clips_v1.5/Push/Push_6_9...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2011 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7eb44d9-f7fa-4caa-a129-70e26a0c0563')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7eb44d9-f7fa-4caa-a129-70e26a0c0563 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7eb44d9-f7fa-4caa-a129-70e26a0c0563');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3da075ba-5de1-455d-9f2a-661262961233\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3da075ba-5de1-455d-9f2a-661262961233')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3da075ba-5de1-455d-9f2a-661262961233 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0e35f0c0-01d1-45d9-be36-f21de0541fd6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e35f0c0-01d1-45d9-be36-f21de0541fd6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 2011,\n  \"fields\": [\n    {\n      \"column\": \"full_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2011,\n        \"samples\": [\n          \"/kaggle/input/aridzip/clips_v1.5/Drink/Drink_17_22.mp4\",\n          \"/kaggle/input/aridzip/clips_v1.5/Sit/Sit_18_15.mp4\",\n          \"/kaggle/input/aridzip/clips_v1.5/Walk/Walk_3_10.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          8,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_categories = [\n",
        "        'Drink', 'Jump', 'Pick', 'Pour', 'Push',\n",
        "        'Run', 'Sit', 'Stand', 'Turn', 'Walk', 'Wave'\n",
        "    ]"
      ],
      "metadata": {
        "id": "qHHe_NPAy-zA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(test_df, model, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Predicting\"):\n",
        "            try:\n",
        "                frames = load_video_frames(row['full_path'])\n",
        "                tensor = preprocess_frames(frames).unsqueeze(0).to(device)\n",
        "                outputs = model(tensor)\n",
        "                pred = torch.argmax(outputs, dim=1).item()\n",
        "            except Exception as e:\n",
        "                # Fallback to class 0 if an error occurs\n",
        "                pred = 0\n",
        "            preds.append(pred)\n",
        "            print(f\"Actual : {action_categories[row['label']]} , Preds : {preds[-1]}\")\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "f9_Vd3Akxf4x"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARID_PATH = \"/kaggle/input/aridzip\"\n",
        "PTH_PATH  = \"/content/pretrained_models/mvit_v2_s_kinetics400.pth\""
      ],
      "metadata": {
        "id": "wbe6dzjyxiFw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df, action_classes = parse_arid_splits(ARID_PATH)\n",
        "print(f\"Total test videos: {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMKXdD12xklS",
        "outputId": "815097e0-4c40-4bec-bd62-7165e749ca80"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total test videos: 2011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model = create_mvitv2_model(num_classes=len(action_classes),\n",
        "                            pretrained_path=PTH_PATH)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BClA6EOJxri5",
        "outputId": "6dc9bb80-92bf-46ce-8286-cf3d8b156ea6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Loaded pretrained weights from /content/pretrained_models/mvit_v2_s_kinetics400.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MViT(\n",
              "  (conv_proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))\n",
              "  (pos_encoding): PositionalEncoding()\n",
              "  (blocks): ModuleList(\n",
              "    (0): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=96, out_features=96, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=96, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=384, out_features=96, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "    )\n",
              "    (1): MultiscaleBlock(\n",
              "      (pool_skip): Pool(\n",
              "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=96, out_features=576, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=768, out_features=192, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.013333333333333334, mode=row)\n",
              "      (project): Linear(in_features=96, out_features=192, bias=True)\n",
              "    )\n",
              "    (2): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=768, out_features=192, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.02666666666666667, mode=row)\n",
              "    )\n",
              "    (3): MultiscaleBlock(\n",
              "      (pool_skip): Pool(\n",
              "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=192, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.04000000000000001, mode=row)\n",
              "      (project): Linear(in_features=192, out_features=384, bias=True)\n",
              "    )\n",
              "    (4): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.05333333333333334, mode=row)\n",
              "    )\n",
              "    (5): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
              "    )\n",
              "    (6): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.08000000000000002, mode=row)\n",
              "    )\n",
              "    (7): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.09333333333333334, mode=row)\n",
              "    )\n",
              "    (8): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.10666666666666667, mode=row)\n",
              "    )\n",
              "    (9): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
              "    )\n",
              "    (10): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
              "    )\n",
              "    (11): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.14666666666666667, mode=row)\n",
              "    )\n",
              "    (12): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.16000000000000003, mode=row)\n",
              "    )\n",
              "    (13): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.17333333333333334, mode=row)\n",
              "    )\n",
              "    (14): MultiscaleBlock(\n",
              "      (pool_skip): Pool(\n",
              "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=384, out_features=2304, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.18666666666666668, mode=row)\n",
              "      (project): Linear(in_features=384, out_features=768, bias=True)\n",
              "    )\n",
              "    (15): MultiscaleBlock(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): MultiscaleAttention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (pool_q): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_k): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (pool_v): Pool(\n",
              "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
              "          (norm_act): Sequential(\n",
              "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (head): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=True)\n",
              "    (1): Linear(in_features=768, out_features=400, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_labels = generate_predictions(test_df, model, device)\n",
        "print(\"Raw predicted labels:\", raw_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "HK7jRVVIx7Ju",
        "outputId": "005b313c-fa66-4c2e-b2e3-b109ae8e41fe"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:   0%|          | 1/2011 [00:06<3:21:26,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 2/2011 [00:10<3:00:12,  5.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 3/2011 [00:16<3:08:34,  5.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 4/2011 [00:21<3:01:10,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 5/2011 [00:28<3:09:28,  5.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 6/2011 [00:33<3:02:45,  5.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 7/2011 [00:38<3:05:14,  5.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 8/2011 [00:44<3:06:28,  5.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 9/2011 [00:49<3:01:03,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 10/2011 [00:56<3:10:58,  5.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 11/2011 [01:01<3:05:22,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 12/2011 [01:06<3:07:26,  5.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 13/2011 [01:12<3:02:55,  5.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 14/2011 [01:18<3:07:54,  5.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 15/2011 [01:23<3:04:08,  5.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 16/2011 [01:29<3:07:31,  5.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 17/2011 [01:34<3:04:53,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 18/2011 [01:40<3:05:45,  5.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 19/2011 [01:46<3:09:02,  5.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 20/2011 [01:51<3:04:52,  5.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 21/2011 [01:57<3:04:18,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 22/2011 [02:02<3:01:00,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 23/2011 [02:08<3:07:31,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 24/2011 [02:13<3:02:17,  5.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|          | 25/2011 [02:18<2:58:29,  5.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|▏         | 26/2011 [02:24<3:04:39,  5.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|▏         | 27/2011 [02:30<3:02:16,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|▏         | 28/2011 [02:36<3:07:00,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|▏         | 29/2011 [02:41<3:03:30,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   1%|▏         | 30/2011 [02:47<3:09:45,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   2%|▏         | 31/2011 [02:52<3:05:04,  5.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   2%|▏         | 32/2011 [02:58<3:06:24,  5.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   2%|▏         | 33/2011 [03:03<2:59:47,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   2%|▏         | 34/2011 [03:08<2:55:19,  5.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   2%|▏         | 35/2011 [03:15<3:08:55,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   2%|▏         | 36/2011 [03:20<3:02:10,  5.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual : Run , Preds : 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   2%|▏         | 36/2011 [03:20<3:03:33,  5.58s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-56-3137695425.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raw predicted labels:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-55-530179380.py\u001b[0m in \u001b[0;36mgenerate_predictions\u001b[0;34m(test_df, model, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Predicting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_video_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-34-2201605700.py\u001b[0m in \u001b[0;36mload_video_frames\u001b[0;34m(video_path, num_frames, sample_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "feG4h7BryJrt",
        "outputId": "74408818-0240-43e6-9fb6-920372907a2d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'raw_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-44-650981488.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAIrAVCRyAgM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}